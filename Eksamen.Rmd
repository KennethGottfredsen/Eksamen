---
title: "Statistical learning og programmering"
author: "Af Kenneth Gottfredsen, Eva Rauff og Sanne Sørensen"
date: "`r Sys.Date()`"
output:
  pdf_document: 
    toc: yes
    df_print: paged
  word_document:
    toc: yes
  html_document:
    toc: yes
    df_print: paged
subtitle: '1. Semesterprojekt. Antal ord:'
header-includes:
- \usepackage{fancyhdr} # Pakke til at justere sidehoved og sidefod.
- \usepackage{lastpage} # Sidetal i højre side af bundmargen.
- \usepackage[danish]{babel} # Alle overskrifter er på Dansk.
latex_engine: xelatex # Xelatex er den gamle engine til TNR.
mainfont: Times New Roman # Times New Roman skrift. 
fontsize: 12pt # Tekststørrelse. 
geometry: margin=1in # Justerer margen.
linestretch: 1.5 # 1.5 linjeafstand. 
documentclass: report # Dokumenttypen.
papersize: a4 # a4 side. 
editor_options: 
  markdown: 
    wrap: sentence
---

<!--- Definerer sidehoved og sidefod --->

```{=tex}
\fancypagestyle{plain}{%
\renewcommand{\headrulewidth}{0pt}%
\fancyhf{}%
\fancyfoot[R]{\footnotesize Side \thepage\,af\,\pageref*{LastPage}}
\setlength\footskip{12.75pt}
}
```
<!--- Justerer sidetypen til plain --->

```{=tex}
\pagestyle{plain}
\pagestyle{fancy}
\thispagestyle{empty}
```
<!--- Sidetal starter fra nul, istedet for 1 --->

\setcounter{page}{0}

<!--- Laver en ny side efter indholdsfortegnelsen --->


\newpage

```{r, Setup, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)

knitr::knit_engines$set(upper = function(options) {
code <- paste(options$code, collapse = "\n")
if (options$eval) 
toupper(code) else code
})
```

I første omgang indlæses `pacman::load`:

```{r, Chunk 1, include=TRUE, eval= TRUE}
# Inden vi går i gang bruger vi pacman() til at installere og indhente relevante
# pakker på samme tid. 
pacman::p_load("tidyverse", "magrittr", "nycflights13", "gapminder",
               "Lahman", "maps", "lubridate", "pryr", "hms", "hexbin",
               "feather", "htmlwidgets", "broom", "pander", "modelr",
               "XML", "httr", "jsonlite", "lubridate", "microbenchmark",
               "splines", "ISLR2", "MASS", "testthat", "leaps", "caret",
               "RSQLite", "class", "babynames", "nasaweather",
               "fueleconomy", "viridis", "readxl", "timeDate", "tinytex",
               "ggbeeswarm", "palmerpenguins", "hms", "RColorBrewer", "boot",
               "openxlsx", "writexl", "PerformanceAnalytics", "car")
```

\newpage

## Import

I første omgang vil vi importere det datasæt vi har fået udleveret til eksamen:

```{r, Chunk 2, include=TRUE, eval= TRUE}
# Indlæser datasæt og gemmer det nye datasæt i et objekt. 
data1 <- read_excel("data/stud_exam_data.xlsx")
 # Dernæst undersøges strukturen i datasættet.
str(data1)
```

Nu har vi fået indlæst datasættet.
Det næste skridt er at transformere de forskellige variabler:

I følgende kode-chunk vil vi rekode og transformere de udvalgte variabler så de 
stemmer overens med eksamensbesvarelsen. Hele kodestumpen vil blive kædet sammen
med 'pipe' funktionen' fra dplyr pakken. Omkodningerne bliver til sidst gemt i 
en ny dataframe som vi kalder data1.

Derefter bruger vi mutate() til at lave en ny kolonne ud fra data1. Først laver
vi en date-variabel, som vi koder til et date objekt med ymd() funktionen fra 
lubridate pakken.

I den næste del anvendes mutate() til, at lave en kolonne der hedder dag, som 
bliver omkodet til en faktor. Dernæst koder vi date til et objekt med ymd() 
funktionen fra lubridate pakken. "lubridate.week.start",1=mandag, istedet for 
søndag som er standardindstillingerne i R. 

Dernæst bruger vi mutate() igen til at danne en ny weekend-variabel der hedder 
weekend_1. I denne sammenhæng vælger vi at fredag, lørdag, søndag og fire andre 
helligdage er 1, ellers er de andre værdier 0. Dette kaldes for en 
dummyvariabel. 

Måned, dag, kamjunk, forvent_lager og weekend_1 er alle kategoriske faktorer.
For at gøre det nemmere at forstå hvad de forskellige værdier udtrykker, 
navngiver vi disse med fct_recode funktionen.

```{r, Chunk 3 - Transformering, include=TRUE, eval= TRUE}
data1 <- data1 %>%
  mutate(date = ymd(date), måned = factor(month(date)),
         kamjunk = factor(kammerjunkere), forvent_lager =
           factor(forventet_l_lager)) %>%
  mutate(dag = as.factor(wday(date, week_start =
                                getOption("lubridate.week.start", 1)))) %>%
  mutate(weekend_1 = as.integer(dag %in% c("5", "6", "7")| date %in%
                                  ymd("2022-04-14", "2022-04-18", "2022-05-26",
                                      "2022-06-06"))) %>%
  mutate(weekend = factor(weekend_1)) %>%
  mutate(data1, kamjunk = fct_recode(kammerjunkere, "ja" = "0",
                                     "nej" = "1")) %>%
  mutate(data1, forvent_lager = fct_recode(forventet_l_lager, "lav" = "1",
                                           "mellem" = "2", "høj" = "3")) %>%
  mutate(data1, måned = fct_recode(måned, "april" = "4", "maj" = "5",
                                   "juni" = "6", "juli" = "7",
                                   "august" = "8")) %>%
  mutate(data1, dag = fct_recode(dag, "mandag" = "1", "tirsdag" = "2",
                                 "onsdag" = "3", "torsdag" = "4",
                                 "fredag" = "5", "lørdag" = "6",
                                 "søndag" = "7")) %>%
  dplyr::select(date, måned, dag, efterspørgsel, kamjunk, forvent_lager,
                weekend_helligdag = weekend)
```

I denne kodechunk vil vi lave en HTTP GET-anmodning til en API fra DMI. Vi skal
bruge adgangen til at få de relevante vejr-variable som vi senere skal bruge i
vores analyse. API'en leverer til slut et objekt i JSON format som bliver
transformeret om til en dataframe i stedet for en liste. 

Først bruger vi base_url og info_url til at anmode om vejrdata fra DMI's API.
req_url bruges til at udvælge specifikke parametre fra API´en. 

```{r, Chunk 4 - Vejrdata fra DMI, include=FALSE, eval= TRUE}

Base_url <- "https://dmigw.govcloud.dk/v2/"	 
Info_url <- "metObs/collections/observation/items?"
Req_url <-  "stationId=06186&datetime=2022-04-01T12%3A00%3A00Z%2F2022-08-30T12%3A00%3A00Z&api-key=1fda8cc2-25bf-45e3-9f43-702fb9ccfdf3&limit=80182" 
# full_url er en sammenkædning af base_url, info_url og reg_url. 
Full_url <- base::paste0(Base_url, Info_url, Req_url)
# Anmoder om at få adgang til apién vha. httr pakken. 
Api_call <- httr::GET(Full_url) 
# Undersøger status fra apién. 200 indikerer at der ikke er en fejl. 
Api_call$status_code 
# Undersøger hvilket format apikaldet er. Her er det json format. 
http_type(Api_call) 
# Undersøger rådata. 
Api_call$content
# Omdanner rådata til en karakter streng. 
api_char <- base::rawToChar(Api_call$content) 
# Konverterer karakterstrengen til et json objekt. 
api_JSON <- jsonlite::fromJSON(api_char, flatten = TRUE)
# laver en variabel som bliver kædet sammen til et json objekt.
list_dmi <- api_JSON
# Laver et nyt objekt som hedder data2 ud fra list_dmi. Denne liste bliver
# konverteret til en dataframe, så vi kan arbejde videre med vores data.
data2 <- as.data.frame(do.call(cbind, list_dmi))

```

I denne kodechunk vil vi transformere den data vi har hentet fra vores API-kald
til nogle mere brugbare data. 

Først bruger vi base_url og info_url til at anmode om vejrdata fra DMI's API.
req_url bruges til at udvælge specifikke parametre fra API´en. 

Derefter bruger vi pivot_wider-funktionen til at sprede variablerne ud i
separate kolonner.

Vi bruger derefter Mutate-funktionen til at konvertere kolonnen
'målingstidspunkt' til en datoformat
Separate-funktionen bruges til at opdele kolonnen 'målingstidspunkt' i to
separate kolonner som vi navngiver 'date' og 'time'.

Filter-funktionen udvælger rækker, der indeholder de første fire characters: 
"12:0". 

```{r, Chunk 5 - Tidy af vejrdata fra DMI, include=TRUE, eval= TRUE}

data2 <- as.data.frame(do.call(cbind, list_dmi))
data2 <- dplyr::select(data2, features.properties.observed,
                       features.properties.value,
                       features.properties.parameterId) %>% 
  rename(værdi = features.properties.value, parameter =
           features.properties.parameterId,
         målingstidspunkt = features.properties.observed) %>%
  pivot_wider(names_from = parameter, values_from = værdi) %>% 
  mutate(målingstidspunkt = as_datetime(målingstidspunkt)) %>%
  separate(målingstidspunkt, into = c('date', 'time'), sep = " ") %>% 
  filter(str_sub(time, 1, 4) == "12:0") %>% 
  mutate(date = as_date(date)) %>%
  mutate(time = as_hms(time)) %>% 
  dplyr::select(-(temp_max_past12h:temp_min_past12h))
```

I nedestående kode-chunk merger vi data1 og data2 til data3 for at beholde alle
observationer i x.

Vi bruger derefter mutate-funktionen til at oprette fire nye variabler i data3 
kaldet temp_gt25_3_dage. Lag-funktionen er brugt til at lave variablerne, som
har opfanget forsinkede værdier fra temp1, temp2 og temp3. Afslutningsvis dannes
variablen 'temp_gt25_3_dage', som måler de dage hvor der har været mere end 
3 dage i træk med >= 25 grader. Det er en dummyvariabel fordi vi bruger if_else. 

```{r, Chunk 6 - Merging af de to datasæt, include=TRUE, eval= TRUE}

data3 <- data1 %>%
left_join(data2, data1, by = c("date" = "date"))
dplyr::select(data3, date, time, weekend_helligdag, everything())


data3 <- data3 %>% 
  mutate(temp1 = lag(temp_max_past1h, 1),
         temp2 = lag(temp_max_past1h, 2),
         temp3 = lag(temp_max_past1h, 3),
         temp1 = if_else(is.na(temp1), 0, temp1),
         temp2 = if_else(is.na(temp2), 0, temp2),
         temp3 = if_else(is.na(temp3), 0, temp3),
         temp_gt25_3_dage = if_else(temp1 >= 25 & temp2 >= 25 & temp3 >= 25,
                                    1, 0))
```

Først identificerer vi outliers i vores dataset data3. Derefter fjerner vi
1 outlier som er 47.

Derefter laver vi en ggplot for at se fordelingen af efterspørgselen af koldskål
i form af en histogram. 

Vi bruger geom_density til at forstå fordelingen og til at forudsige fordelingen
af koldskål i en anden undersøgelse.

Man kan se at fordelingen er størst omkring 500 liter koldskål.

```{r, Chunk 7 - Histogram over efterspørgsel, include=TRUE, eval= TRUE}

boxplot.stats(data3$efterspørgsel)$out

data3 <- data3 %>%
  filter(efterspørgsel > 47)

ggplot(data3, aes(x = efterspørgsel)) +
 geom_histogram(aes(y =..density..), colour = "black",
                fill = "gray", binwidth = 60) +
 geom_density(alpha=0.5, fill="#FF6666", adjust=1.5) +
  labs(title = "Histogram over butikkernes efterspørgsel af koldskål",
       subtitle = "Undersøger om efterspørgslen er normaltfordelt",
       y = "Antal observationer",
       x = "Butikkernes efterspørgsel af koldskål",
       caption = "Kilde: Thise Mejeri 2022") +
  ggeasy::easy_center_title() + # Centrerer titlen.
  theme( plot.title = element_text(hjust = 0.5, size = 16),
         plot.subtitle = element_text(hjust = 0.5, size = 14),
         plot.caption = element_text(hjust = 1, face = "italic", size = 10)) +
  xlim(150, 1000) + ylim(0, 0.0035)

```

På følgende kode-chunk har vi lavet et boxplot til at vise den statistiske
variationen af lagerbeholdningen og efterspørgsel. 

Her kan man se at median-efterspørgslen stiger når man går fra høj til lav
forventet lagerbeholdning af koldskål. Dette tyder også på at der er en 
sammenhæng mellem de 2 variabler.

```{r, Chunk 8 - Boxplot over lagerbeholdning og efterspørgsel, include=TRUE,eval= TRUE}

ggplot(data = data3, mapping = aes(x = forvent_lager, y = efterspørgsel, fill =
                                     forvent_lager)) +
  stat_boxplot(geom = 'errorbar') + # whiskers. 
  geom_boxplot() + 
  labs(title = "Lagerbeholdningen og efterspørgsel af koldskål",
       subtitle = "Variationen ift. den forventede lagerbeholdning og koldskål", 
       caption = "Kilde: Tal fra DMI 2002. Fra perioden 1/4/22-30/8/22",
       y = "Butikkernes efterspørgsel på koldskål (ltr)",
       x = "Butikkens forventede lagerbeholdning") + # Undgår overplotting
  geom_beeswarm(dodge.width=3, cex =1, color = "black") + # Justerer boksbredden
  ggeasy::easy_center_title() + # Centrerer titlen. 
  theme( plot.title = element_text(hjust = 0.5, size = 16),
         plot.subtitle = element_text(hjust = 0.5, size = 14), 
         plot.caption = element_text(hjust = 1.3, face = "italic",size = 10 )) +
  scale_fill_brewer(palette = "Pastel2")
```

I næste kode-chunk har vi lavet et boxplot som viser fordelingen af
efterspørgslen i forhold til om 25% af butikkerne er løbet tør for kammerjunkere
eller ej.
På baggrund af plottet kan vi se at hvis butikkerne ikke har kammerjunkere på
lageret så falder efterspørgslen. Konklusionen er at efterspørgslen på koldskål
stiger når de er løbet tør for kammerjunkere.


```{r, Chunk 9 - Boxplot over efterspørgsel og kammerjunkere, include=TRUE, eval= TRUE}

ggplot(data = data3, mapping = aes(x = kamjunk, y = efterspørgsel, fill =
                                     kamjunk)) +
  stat_boxplot(geom = 'errorbar') +
  geom_boxplot() + 
  labs(title = "Kammerjunkere og efterspørgsel af koldskål",
  subtitle = "Variationen ift. den forventede lagerbeholdning af kammerjunker
  og koldskål",
  caption = "Kilde: Tal fra DMI 2002. Fra perioden 1/4/22-30/8/22",
  y = "Butikkernes efterspørgsel på koldskål (L).",
  x = "Mere end 25% af butikkerne er løbet tør for kammerjunkere") +
  ggeasy::easy_center_title() + # Centrerer titlen. 
  geom_beeswarm(dodge.width=3,cex=0.5, color = "black") + # Justerer boksbredden.
  theme( plot.title = element_text(hjust = 0.5, size = 16),
         plot.subtitle = element_text(hjust = 0.5, size = 14), 
         plot.caption = element_text(hjust = 1.5, face = "italic",
                                     size = 10 )) +
  scale_fill_brewer(palette = "Pastel2")
```

Forneden har vi lavet et boxplot som viser sammenhængen mellem måned og
efterspørgslen af koldskål. 
Det er tydeligt at se at efterspørgslen stiger fra april-juli og derefter falder
efterspørgslen i august. Hvilket kan tyde på at efterspørgselen af koldskål
hænger sammen med sommerperioden.

```{r, Chunk 10 - Boxplot over efterspørgsel og måned, include=TRUE, eval= TRUE}
ggplot(data = data3, mapping = aes(x = måned, y = efterspørgsel,
                                   fill = måned)) +
  stat_boxplot(geom = 'errorbar') +
  geom_boxplot() + 
  labs(title = "Måned og efterspørgsel af koldskål",
       subtitle = "Variationen ift. måned og efterspørgelsen af koldskål",
       caption = "Kilde: Tal fra DMI 2002. Fra perioden 1/4/22-30/8/22",
       y = "Butikkernes efterspørgsel på koldskål (L).",
       x = "Måned") +
  ggeasy::easy_center_title() + # Centrerer titlen. 
  geom_beeswarm(dodge.width=3,cex=0.5, color = "black") + # Justerer boksbredden.
  theme( plot.title = element_text(hjust = 0.5, size = 16),
         plot.subtitle = element_text(hjust = 0.5, size = 14), 
         plot.caption = element_text(hjust = 1.3, face =
                                       "italic", size = 10 )) +
  scale_fill_brewer(palette = "Pastel2")
```


```{r, Chunk 11 - Scatterplot af temperatur og efterspørgsel, include=TRUE, eval= TRUE}
# Basic scatter plot med prediktionsinterval. 
summary(efterspørgsel)
predict(model1,data.frame(efterspørgsel=(c(520))), interval = "prediction", level = 0.95)
model1 <- lm(efterspørgsel ~ temp_max_past1h, data = data3)
prædiktion <- predict(model1, interval = "prediction", level = 0.95)
new_df <- cbind(data3, prædiktion)
ggplot(new_df, aes(temp_max_past1h, efterspørgsel))+
    geom_point() +
    geom_line(aes(y=lwr), color = "red", linetype = "dashed")+
    geom_line(aes(y=upr), color = "red", linetype = "dashed")+
    geom_smooth(method=lm, se=TRUE) + 
    labs(title = "Sammenhængen mellem temperatur og efterspørgsel af koldskål",
    subtitle = "Linelær regression der viser relationen mellem den forventede lagerbeholdning og koldskål",
    caption = "Kilde: tal fra DMI 2002 fra perioden 1/4/22-30/8/22",
    y = "Butikkernes efterspørgsel på koldskål (ltr.)",
    x = "Maks temperatur hver time (celcius)") +
ggeasy::easy_center_title() + # Centrerer titlen. 
theme( plot.title = element_text(hjust = 0.5, size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 14), 
plot.caption = element_text(hjust = 1, face = "italic", size = 10 ))+
xlim(5, 30.70) + ylim(220, 900)
```


I dette afsnit vil vi gå i gang med analysen.

```{r, Chunk 12 - Statistisk analyse, include=TRUE, eval= TRUE, warning=FALSE}

# Tester for samvariation og multikolinearitet på de kontinuerte variabler. 
cor_matrice <- data3 |>  
  dplyr::select(efterspørgsel, temp_min_past1h,
                temp_dry, temp_max_past1h,                                                     temp_mean_past1h, temp1, temp2, temp3) 
chart.Correlation(cor_matrice, histogram = TRUE, method = "pearson")
# Der er stærk multikolinearitet, det kan være et problem ift. tolkningen af
# vores multible regressionsmodel. Dette har også en negativ indvirkning på 
# modellens pålidelighed.




predi

glimpse(data3)

attach(data3)
lm.fit1 = lm(efterspørgsel ~ forvent_lager + weekend_helligdag + kamjunk + temp_gt25_3_dage + temp_max_past1h)
vif(lm.fit1) # VIF > 1 indikerer at der er inflation i variansen på alle variabler. 
summary(lm.fit1)
plot(lm.fit1)
# R^2 indikerer at de uafhængige variable forklarer 58% af variansens i data. 

 

lm.fit2 = lm(efterspørgsel ~ 1) # simpel model
summary(lm.fit2)

 

lm.fit3 = lm(efterspørgsel ~ temp_max_past1h^2) # melllem model. 
summary(lm.fit3)

 

lm.fit4 = lm(efterspørgsel ~ temp_max_past1h + temp_max_past1h^5) # ekstrem model 
summary(lm.fit4)

x <- data3$temp_max_past1h
y <- data3$efterspørgsel
data <- data.frame(y, x)
data
set.seed(1)
cv.error <- rep(0, 5)
for (i in 1:5) {
  glm.fit <- glm(y~poly(x , i), data = )
  cv.error[i] <- cv.glm(data , glm.fit)$delta [1]
}
cv.error


cv.error1 <- rep(0, 10)
for (i in 1:10) {
  glm.fit1 <- glm(efterspørgsel ~ poly(temp_max_past1h, i), data = data3)
  cv.error1[i] <- cv.glm(data3, glm.fit1)$delta[1]
}
cv.error1
summary(glm.fit1)

cv.error1 <- rep(0, 10)
for (i in 1:10) {
  glm.fit2 <- glm(efterspørgsel ~ poly(temp_max_past1h, i), data = data3)
  cv.error1[i] <- cv.glm(data3, glm.fit1)$delta[1]
}
cv.error1
summary(glm.fit1)
 

cv.error1 <- rep(0, 10)
for (i in 1:10) {
  glm.fit3 <- glm(efterspørgsel ~ poly(temp_max_past1h, i), data = data3)
  cv.error1[i] <- cv.glm(data3, glm.fit1)$delta[1]
}
cv.error1
summary(glm.fit1)
 
 


x <- data3$temp_max_past1h
y <- data3$efterspørgsel
data <- data.frame(y, x)

ggplot(data3, mapping = aes(x=x, y=y)) + 
  geom_point(alpha=1/3) +
  geom_smooth(method="glm", formula = y ~ poly(x, 1, raw=TRUE), se=FALSE, colour="blue") +
  geom_smooth(method="glm", formula = y ~ poly(x, 3, raw=TRUE), se=FALSE, colour="green") +
  geom_smooth(method="glm", formula = y ~ poly(x, 22, raw=TRUE), se=FALSE, colour="red") +
geom_point(data=data3, mapping = aes(x=x, y=y), alpha=1/3) + 
  labs(title = "Sammenligning af tre regressionsmodeller",
caption = "Kilde: Tal fra DMI 2002 fra perioden 1/4/22-30/8/22",
y = "Butikkernes efterspørgsel på koldskål (Liter)",
x = "Maks temperatur pr.time (Celcius)") +
ggeasy::easy_center_title() + # Centrerer titlen. 
theme( plot.title = element_text(hjust = 0.5, size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 14), 
plot.caption = element_text(hjust = 1, face = "italic", size = 10 ))+
xlim(5, 30.70) + ylim(220, 850) 
```



\newpage

## Tidy

\newpage

## Transformer

\newpage

## Visualiser

\newpage

## Model

\newpage

## Kommunikér/analyse

## Sessioninformation

For at højne reproducerbarheden printes der en udskrift om den nuværende R session:

```{r, Chunk 20 - Info om nuværnde R session, include=TRUE, eval= TRUE}
SI <- sessionInfo(package = NULL) # Udskriver en liste om denne R session.  
```

## Litteratur

## Bilag
